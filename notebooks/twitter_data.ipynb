{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first part of spark activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the json file, and filter the trending and english tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file took 2.469 seconds\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "input = sc.textFile(\"../data/raw/Datasets/Tweets/tweets2.json\")\n",
    "t1 = time()-t0\n",
    "tweet = input.map(lambda x: json.loads(x))\n",
    "\n",
    "\n",
    "print(\"read file took {} seconds\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 727497507375181824, 'name': 'Carlos Gonz√°lez \\uf8ff', 'text': '#mecagaandardetraje #findelcomunicado https://t.co/e7wf6vPIw7', 'lang': 'und'}\n",
      "{'id': 727497507362734080, 'name': 'AmeriGirl', 'text': 'RT @NolteNC: Morning Joe gives huge credit to Hillary for confronting a critic but laughs hysterically when Cruz \"shows up\" to do same.', 'lang': 'en'}\n"
     ]
    }
   ],
   "source": [
    "# Filter English Tweets\n",
    "english_tweets = tweet.filter(lambda t: \"en\" in t[\"lang\"]).map(lambda t:{\"id\":t[\"id\"],\"name\":t[\"user\"][\"name\"],\"text\":t[\"text\"], \"lang\":t[\"lang\"]})\n",
    "trendings= tweet.filter(lambda t: \"#\" in t[\"text\"][0]).map(lambda t:{\"id\":t[\"id\"],\"name\":t[\"user\"][\"name\"],\"text\":t[\"text\"], \"lang\":t[\"lang\"]})\n",
    "print (trendings.first())\n",
    "print(english_tweets.first())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the sequence file, in order to save the filtered tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727497507375181824, '#mecagaandardetraje #findelcomunicado https://t.co/e7wf6vPIw7')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, shutil\n",
    "\n",
    "# if the outputs files exist, remove them\n",
    "if os.path.exists(\"../reports/sequence_files\"):\n",
    "    shutil.rmtree(\"../reports/sequence_files\")\n",
    "\n",
    "    \n",
    "trending_tweet = trendings.map(lambda t: (t[\"id\"], t[\"text\"]))\n",
    "\n",
    "# Save the trending tweet as sequence file.\n",
    "trending_tweet.saveAsSequenceFile(\"../reports/sequence_files\")\n",
    "print (trending_tweet.first())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count words fand using the sequence file(just the filtered data) as the input \n",
    "and then save the results into text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = sc.textFile(\"../reports/sequence_files/part-00000\")\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "counts.saveAsTextFile(\"../reports/results\")\n",
    "counts.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the saved sequence file and then select the first 10 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read sequence file took  0.402 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "seq = sc.sequenceFile(\"../reports/sequence_files\", \n",
    "                      \"org.apache.hadoop.io.Text\", \n",
    "                      \"org.apache.hadoop.io.IntWritable\")\n",
    "\n",
    "t1 = time()-t0\n",
    "\n",
    "print(\"read sequence file took  {} seconds\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the first 10 tweets into a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../reports/top_10\"): \n",
    "    shutil.rmtree(\"../reports/top_10\")\n",
    "    \n",
    "# Write Tweets into a text file.\n",
    "top_10 = sc.parallelize(seq.take(10))\n",
    "top_10.saveAsTextFile(\"../reports/top_10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
